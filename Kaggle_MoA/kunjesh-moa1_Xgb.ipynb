{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")\n#import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nss_krr = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_final=pd.concat([pd.get_dummies(train_features.iloc[:,1:4]),train_features.iloc[:,4:]],axis=1)\n#print(train_features_final)\ntest_features_final=pd.concat([pd.get_dummies(test_features.iloc[:,1:4]),test_features.iloc[:,4:]],axis=1)\n#test_features_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_final1=(train_features_final-train_features_final.mean())/train_features_final.std()\ntest_features_final1=(test_features_final-test_features_final.mean())/test_features_final.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nans_df=pd.DataFrame()\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfor i in range(len(train_targets.columns)-1):\n\n    X_train, X_test, y_train, y_test = train_test_split(train_pca,train_targets.iloc[:,i+1], test_size=0.03)\n\n\n    model = keras.Sequential([\n    \n        keras.layers.Dense(256, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(128, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(64, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(32, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(16, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(8, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(2)\n    ])\n\n    #model.summary()\n\n    model.compile(optimizer='adam',\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n    model.fit(X_train, y_train, epochs=50)\n\n    probability_model = tf.keras.Sequential([model,tf.keras.layers.Softmax()])\n\n    predictions = probability_model.predict(test_pca)\n    ans_df=pd.concat([ans_df,pd.DataFrame(predictions[:,1])],axis=1)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ans_df=pd.DataFrame()\n'''\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\n\ndef multiprocessing_func(i):\n    \n    X_train, X_test, y_train, y_test = train_test_split(train_pca,train_targets.iloc[:,i+1], test_size=0.03)\n\n\n    model = keras.Sequential([\n    \n        keras.layers.Dense(256, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(128, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(64, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(32, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(16, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(8, activation='relu',input_shape=[len(X_train.columns)]),\n        keras.layers.Dense(2)\n    ])\n\n    #model.summary()\n\n    model.compile(optimizer='adam',\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n    model.fit(X_train, y_train, epochs=25)\n\n    probability_model = tf.keras.Sequential([model,tf.keras.layers.Softmax()])\n\n    predictions = probability_model.predict(test_pca)\n    return(predictions)\n    #ans_df=pd.concat([ans_df,pd.DataFrame(predictions[:,1])],axis=1)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport multiprocessing\npool=multiprocessing.Pool()\nresult=pool.map(multiprocessing_func, range(len(train_targets.columns)-1))\npool.close()\npool.join()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ans_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Logit\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(class_weight=\"balanced\")\nfinal_ans=pd.DataFrame()\n#train_targets.iloc[:,1]\nfor i in range(len(train_targets.columns)-1):\n#    train_targets.iloc[:,i+1]\n    lr.fit(train_features_final1, train_targets.iloc[:,i+1])\n    y_pred = lr.predict_proba(test_features_final1)\n    final_ans=pd.concat([final_ans,pd.DataFrame(y_pred).iloc[:,1]],axis=1)\n    #print(i)\n    \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Logit on PCA\ncombined_pca=pd.concat([train_features_final1.iloc[:,5:],test_features_final1.iloc[:,5:]],axis=0).reset_index().iloc[:,1:]\n#from 23814: test data\n#combined_pca\nfrom sklearn.decomposition import PCA\npca_combined = PCA(n_components=400)\nprincipalComponents = pca_combined.fit_transform(combined_pca)\n#print(principalComponents.shape)\n#pca_combined.explained_variance_ratio_.sum()\nprincipalComponents_train=pd.DataFrame(principalComponents[:23814,:])\nprincipalComponents_test=pd.DataFrame(principalComponents[23814:,:])\n#principalComponents_test.columns==principalComponents_train.columns\n#principalComponents_test\ntrain_pca=pd.concat([train_features_final1.iloc[:,0:5],principalComponents_train],axis=1)\ntest_pca=pd.concat([test_features_final1.iloc[:,0:5],principalComponents_test],axis=1)\n\n\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(class_weight=\"balanced\")\nfinal_ans=pd.DataFrame()\nfor i in range(len(train_targets.columns)-1):\n    lr.fit(train_pca, train_targets.iloc[:,i+1])\n    y_pred = lr.predict_proba(test_pca)\n    final_ans=pd.concat([final_ans,pd.DataFrame(y_pred).iloc[:,1]],axis=1)\n    #print(i)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Xgboost on PCA\n#from sklearn.linear_model import LogisticRegression\ncombined_pca=pd.concat([train_features_final1.iloc[:,5:],test_features_final1.iloc[:,5:]],axis=0).reset_index().iloc[:,1:]\n#from 23814: test data\n#combined_pca\nimport time\nimport xgboost as xgb\nfrom sklearn.decomposition import PCA\npca_combined = PCA(n_components=400)\nprincipalComponents = pca_combined.fit_transform(combined_pca)\n#print(principalComponents.shape)\n#pca_combined.explained_variance_ratio_.sum()\nprincipalComponents_train=pd.DataFrame(principalComponents[:23814,:])\nprincipalComponents_test=pd.DataFrame(principalComponents[23814:,:])\n#principalComponents_test.columns==principalComponents_train.columns\n#principalComponents_test\ntrain_pca=pd.concat([train_features_final1.iloc[:,0:5],principalComponents_train],axis=1)\ntest_pca=pd.concat([test_features_final1.iloc[:,0:5],principalComponents_test],axis=1)\n\nfinal_ans=pd.DataFrame()\nxg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.4, learning_rate = 0.075,\n                max_depth = 8, alpha = 0.1, n_estimators = 150)\ntic=time.time()\nfor i in range(len(train_targets.columns)-1):\n#xg_reg.fit(X_train,y_train)\n    xg_reg.fit(train_pca,train_targets.iloc[:,i+1])\n    preds = xg_reg.predict_proba(test_pca)\n    final_ans=pd.concat([final_ans,pd.DataFrame(preds).iloc[:,1]],axis=1)\n    if(i%25==0):\n        print ((time.time()-tic)/60) \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Xgboost on All data\n#from sklearn.linear_model import LogisticRegression\nimport time\nimport xgboost as xgb\n\nfinal_ans=pd.DataFrame()\nxg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.075,\n                max_depth = 8, alpha = 0.12, n_estimators = 200)\n#tic=time.time()\n\nfor i in range(len(train_targets.columns)-1):\n    xg_reg.fit(train_features_final1,train_targets.iloc[:,i+1])\n    preds = xg_reg.predict_proba(test_features_final1)\n    final_ans=pd.concat([final_ans,pd.DataFrame(preds).iloc[:,1]],axis=1)\n#    if(i%25==0):\n#        print ((time.time()-tic)/60) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_ans ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final_ans[final_ans<0.005]=0\n#final_ans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_ans1=pd.concat([ss_krr.sig_id,final_ans],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_ans1.columns=ss_krr.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final_ans1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_ans1.to_csv('./submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"submission.csv\")\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}